{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9898672",
   "metadata": {},
   "source": [
    "\n",
    "# storage.ipynb â€” Storage & Validation\n",
    "\n",
    "This notebook persists the **clean DataFrame** into:\n",
    "- **SQLite** (table: `university_rankings`)\n",
    "- **Parquet** (columnar format)\n",
    "\n",
    "It also validates by reading both back and comparing row counts and checksums.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d5b87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "\n",
    "CLEAN_CSV = Path(\"./data_clean/rankings_clean.csv\")\n",
    "DB_PATH = Path(\"./rankings.db\")\n",
    "PARQUET_PATH = Path(\"./rankings.parquet\")\n",
    "TABLE = \"university_rankings\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ed8f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_clean(path: Path) -> pd.DataFrame:\n",
    "    return pd.read_csv(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f32d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_sqlite(df: pd.DataFrame, db_path: Path, table: str) -> None:\n",
    "    with sqlite3.connect(db_path) as con:\n",
    "        df.to_sql(table, con, if_exists=\"replace\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819ae434",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_parquet(df: pd.DataFrame, path: Path) -> None:\n",
    "    df.to_parquet(path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c1539",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_sqlite(db_path: Path, table: str) -> pd.DataFrame:\n",
    "    with sqlite3.connect(db_path) as con:\n",
    "        return pd.read_sql_query(f\"SELECT * FROM {table}\", con)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0193a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_parquet(path: Path) -> pd.DataFrame:\n",
    "    return pd.read_parquet(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e34189",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def df_checksum(df: pd.DataFrame) -> str:\n",
    "    # Simple checksum for validation (order-independent by sorting by primary key if present)\n",
    "    key_cols = [c for c in [\"University\", \"Year\"] if c in df.columns]\n",
    "    df2 = df.sort_values(key_cols) if key_cols else df.copy()\n",
    "    payload = df2.to_csv(index=False).encode(\"utf-8\")\n",
    "    return hashlib.md5(payload).hexdigest()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acaf5e3",
   "metadata": {},
   "source": [
    "\n",
    "# ---- Execute storage and validation ----\n",
    "clean = load_clean(CLEAN_CSV)\n",
    "print(\"Clean rows:\", len(clean))\n",
    "\n",
    "to_sqlite(clean, DB_PATH, TABLE)\n",
    "to_parquet(clean, PARQUET_PATH)\n",
    "print(\"Saved SQLite and Parquet.\")\n",
    "\n",
    "back_sql = read_sqlite(DB_PATH, TABLE)\n",
    "back_parq = read_parquet(PARQUET_PATH)\n",
    "print(\"Back from SQLite:\", len(back_sql), \"rows\")\n",
    "print(\"Back from Parquet:\", len(back_parq), \"rows\")\n",
    "\n",
    "print(\"Checksum (orig):\", df_checksum(clean))\n",
    "print(\"Checksum (sqlite):\", df_checksum(back_sql))\n",
    "print(\"Checksum (parquet):\", df_checksum(back_parq))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}