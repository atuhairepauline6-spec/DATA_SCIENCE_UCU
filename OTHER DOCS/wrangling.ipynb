{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67cb19b5",
   "metadata": {},
   "source": [
    "\n",
    "# wrangling.ipynb — Cleaning & Structuring\n",
    "\n",
    "This notebook loads the **raw rankings CSV** from `acquisition.ipynb`, performs cleaning, type conversion,\n",
    "feature engineering, and validation, and outputs a **clean pandas DataFrame**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43104b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "RAW_CSV = Path(\"./data_raw/rankings_raw.csv\")\n",
    "CLEAN_DIR = Path(\"./data_clean\")\n",
    "CLEAN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CLEAN_CSV = CLEAN_DIR / \"rankings_clean.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ef316",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_raw(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, dtype=str, keep_default_na=False)\n",
    "    # Strip whitespace\n",
    "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e580a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def coerce_rank(val: str) -> float | np.nan:\n",
    "    \"\"\"Convert rank strings like '101-150', '1', 'N/A', '—' to numeric (use start of range).\n",
    "    Returns NaN when not parseable.\n",
    "    \"\"\"\n",
    "    if not isinstance(val, str) or val.strip() == \"\":\n",
    "        return np.nan\n",
    "    s = val.strip()\n",
    "    # Remove dagger/footnote † or other stray symbols\n",
    "    s = re.sub(r\"[†‡*]+\", \"\", s)\n",
    "    # Ranges like '101-150' -> 101\n",
    "    m = re.match(r\"^(\\d+)[\\-–]\\d+$\", s)\n",
    "    if m:\n",
    "        return float(m.group(1))\n",
    "    # Plain integers\n",
    "    m = re.match(r\"^\\d+$\", s)\n",
    "    if m:\n",
    "        return float(m.group(0))\n",
    "    # N/A, -, etc.\n",
    "    if s.lower() in {\"n/a\", \"na\", \"-\", \"—\"}:\n",
    "        return np.nan\n",
    "    # Fallback: extract first number\n",
    "    m = re.search(r\"\\d+\", s)\n",
    "    return float(m.group(0)) if m else np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0ab569",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def coerce_score(val: str) -> float | np.nan:\n",
    "    \"\"\"Convert score strings to float; strip non-numeric except decimal point.\"\"\"\n",
    "    if not isinstance(val, str) or val.strip() == \"\":\n",
    "        return np.nan\n",
    "    s = val.strip()\n",
    "    s = re.sub(r\"[†‡*%]+\", \"\", s)  # remove footnotes and % if present\n",
    "    s = re.sub(r\"[^0-9.]+\", \"\", s) # keep digits and dot\n",
    "    try:\n",
    "        return float(s) if s != \"\" else np.nan\n",
    "    except ValueError:\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Region mapping (simple heuristic — extend as needed)\n",
    "REGION_MAP = {\n",
    "    \"United States\": \"North America\", \"Canada\": \"North America\", \"Mexico\": \"North America\",\n",
    "    \"United Kingdom\": \"Europe\", \"Germany\": \"Europe\", \"France\": \"Europe\", \"Italy\": \"Europe\", \"Spain\": \"Europe\",\n",
    "    \"Netherlands\": \"Europe\", \"Sweden\": \"Europe\", \"Norway\": \"Europe\", \"Finland\": \"Europe\", \"Denmark\": \"Europe\",\n",
    "    \"Switzerland\": \"Europe\", \"Belgium\": \"Europe\", \"Ireland\": \"Europe\", \"Portugal\": \"Europe\", \"Austria\": \"Europe\",\n",
    "    \"Russia\": \"Europe\", \"Poland\": \"Europe\", \"Czech Republic\": \"Europe\", \"Greece\": \"Europe\", \"Hungary\": \"Europe\",\n",
    "    \"Turkey\": \"Asia\", \"China\": \"Asia\", \"Japan\": \"Asia\", \"South Korea\": \"Asia\", \"India\": \"Asia\",\n",
    "    \"Singapore\": \"Asia\", \"Hong Kong\": \"Asia\", \"Taiwan\": \"Asia\", \"Malaysia\": \"Asia\", \"Thailand\": \"Asia\",\n",
    "    \"Philippines\": \"Asia\", \"Indonesia\": \"Asia\", \"Pakistan\": \"Asia\", \"Bangladesh\": \"Asia\", \"United Arab Emirates\": \"Asia\",\n",
    "    \"Saudi Arabia\": \"Asia\", \"Qatar\": \"Asia\", \"Israel\": \"Asia\", \"Iran\": \"Asia\", \"Lebanon\": \"Asia\",\n",
    "    \"Australia\": \"Oceania\", \"New Zealand\": \"Oceania\",\n",
    "    \"Brazil\": \"South America\", \"Argentina\": \"South America\", \"Chile\": \"South America\", \"Colombia\": \"South America\", \"Peru\": \"South America\",\n",
    "    \"South Africa\": \"Africa\", \"Egypt\": \"Africa\", \"Nigeria\": \"Africa\", \"Kenya\": \"Africa\", \"Uganda\": \"Africa\", \"Ghana\": \"Africa\", \"Ethiopia\": \"Africa\", \"Morocco\": \"Africa\", \"Algeria\": \"Africa\", \"Tunisia\": \"Africa\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af9e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wrangle(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Standardize columns\n",
    "    cols = {c.lower().strip(): c for c in df.columns}\n",
    "    # Try flexible access\n",
    "    def get_col(*names):\n",
    "        for n in names:\n",
    "            for c in df.columns:\n",
    "                if c.strip().lower() == n.lower():\n",
    "                    return c\n",
    "        return None\n",
    "\n",
    "    col_year = get_col(\"year\")\n",
    "    col_rank = get_col(\"rank\", \"world rank\")\n",
    "    col_name = get_col(\"university\", \"institution\", \"name\")\n",
    "    col_country = get_col(\"country\")\n",
    "    col_score = get_col(\"overall_score\", \"overall score\", \"score\", \"overall\")\n",
    "\n",
    "    # Minimal subset\n",
    "    out = pd.DataFrame({\n",
    "        \"Year\": df[col_year] if col_year else np.nan,\n",
    "        \"Rank\": df[col_rank] if col_rank else np.nan,\n",
    "        \"University\": df[col_name] if col_name else df.iloc[:, 0],\n",
    "        \"Country\": df[col_country] if col_country else np.nan,\n",
    "        \"Overall_Score\": df[col_score] if col_score else np.nan,\n",
    "    }).copy()\n",
    "\n",
    "    # Missing data handling for Rank\n",
    "    out[\"Rank_num\"] = out[\"Rank\"].apply(coerce_rank)\n",
    "\n",
    "    # Strategy: drop rows with missing rank (justify in report)\n",
    "    before = len(out)\n",
    "    out = out[~out[\"Rank_num\"].isna()].copy()\n",
    "    after = len(out)\n",
    "    dropped = before - after\n",
    "    print(f\"Dropped {dropped} rows with missing/unparseable rank.\")\n",
    "\n",
    "    # Convert Year to int if possible\n",
    "    out[\"Year\"] = pd.to_numeric(out[\"Year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # Score conversion\n",
    "    out[\"Overall_Score_num\"] = out[\"Overall_Score\"].apply(coerce_score)\n",
    "\n",
    "    # Feature engineering: Global_Region\n",
    "    out[\"Global_Region\"] = out[\"Country\"].map(REGION_MAP).fillna(\"Other/Unknown\")\n",
    "\n",
    "    # Normalization: scale Overall_Score_num to [0,1]\n",
    "    scaler = MinMaxScaler()\n",
    "    score_vals = out[[\"Overall_Score_num\"]].fillna(0.0)  # treat missing as 0 for scaling\n",
    "    out[\"Overall_Score_Normalized\"] = scaler.fit_transform(score_vals)\n",
    "\n",
    "    # Primary key uniqueness: (University, Year)\n",
    "    out[\"University\"] = out[\"University\"].astype(str).str.strip()\n",
    "    out = out.drop_duplicates(subset=[\"University\", \"Year\"], keep=\"first\")\n",
    "    dup_check = out.duplicated(subset=[\"University\", \"Year\"], keep=False).sum()\n",
    "    assert dup_check == 0, \"Duplicate (University, Year) keys remain!\"\n",
    "\n",
    "    # Final tidy types\n",
    "    out = out.rename(columns={\n",
    "        \"Rank_num\": \"Rank_int\",\n",
    "        \"Overall_Score_num\": \"Overall_Score_float\"\n",
    "    })\n",
    "    # Order columns\n",
    "    final_cols = [\n",
    "        \"Year\", \"University\", \"Country\", \"Global_Region\",\n",
    "        \"Rank_int\", \"Overall_Score_float\", \"Overall_Score_Normalized\",\n",
    "        \"Rank\", \"Overall_Score\"  # keep original raw strings for traceability\n",
    "    ]\n",
    "    out = out[final_cols]\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79aa621",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Run wrangling ----\n",
    "raw = load_raw(RAW_CSV)\n",
    "print(f\"Raw shape: {raw.shape}\")\n",
    "clean = wrangle(raw)\n",
    "print(f\"Clean shape: {clean.shape}\")\n",
    "clean.to_csv(CLEAN_CSV, index=False)\n",
    "clean.head()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}